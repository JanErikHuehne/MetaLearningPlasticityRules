{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH to NAS mount \n",
    "PATH = '/home/ge84yes/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions \n",
    "\n",
    "def list_all_subfolders(start_path):\n",
    "    subfolders = []\n",
    "    for root, dirs, _ in os.walk(start_path):\n",
    "        for d in dirs:\n",
    "            subfolders.append(os.path.join(root, d))\n",
    "    return subfolders\n",
    "\n",
    "\n",
    "\n",
    "def list_direct_files(folder_path):\n",
    "    return [\n",
    "        os.path.join(folder_path, f)\n",
    "        for f in os.listdir(folder_path)\n",
    "        if os.path.isfile(os.path.join(folder_path, f))\n",
    "    ]\n",
    "\n",
    "# 2) Worker that returns a tuple of values (to avoid shared-list contention)\n",
    "def parse_one(file):\n",
    "    with open(file, \"rb\") as f:      # rb can be slightly faster\n",
    "        jd = json.load(f)\n",
    "    lr = jd[\"long_run\"]\n",
    "    # Note: Your original code swapped ee/ie names; use the keys you meant:\n",
    "    pruning_ee = lr[\"pruning_rate_ee\"]\n",
    "    pruning_ie = lr[\"pruning_rate_ie\"]\n",
    "    big_ee = lr[\"big_weights_ee\"]\n",
    "    big_ie = lr[\"big_weights_ie\"]\n",
    "    rates_e = lr[\"rates_e\"]\n",
    "    rates_i = lr[\"rates_i\"]\n",
    "    return pruning_ee, pruning_ie, big_ee, big_ie, rates_e, rates_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract all possible combinations of folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_1_folders = list_all_subfolders(PATH)\n",
    "level_2_folders = list(set([e.lower() for e in string.ascii_letters]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build list of files once\n",
    "dirs = [Path(PATH) / lv1 / lv2 for lv1 in level_1_folders for lv2 in level_2_folders]\n",
    "print(len(dirs))\n",
    "dirs = [d for d in tqdm(dirs) if d.exists()]\n",
    "print(len(dirs))\n",
    "files = []\n",
    "for d in tqdm(dirs):\n",
    "    # replace with your own list_direct_files if needed\n",
    "    files.extend(list_direct_files(str(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parallize the reading of files, NAS is very slow when it comes to I/O operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Run in parallel and aggregate\n",
    "all_pruning_ee, all_pruning_ie = [], []\n",
    "all_bigweights_ee, all_bigweights_ie = [], []\n",
    "all_rates_e, all_rates_i = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=min(32, (os.cpu_count() or 4) * 5)) as ex:\n",
    "    for res in tqdm(ex.map(parse_one, files, chunksize=50), total=len(files)):\n",
    "        p_ee, p_ie, bw_ee, bw_ie, r_e, r_i = res\n",
    "        all_pruning_ee.append(p_ee)\n",
    "        all_pruning_ie.append(p_ie)\n",
    "        all_bigweights_ee.append(bw_ee)\n",
    "        all_bigweights_ie.append(bw_ie)\n",
    "        all_rates_e.append(r_e)\n",
    "        all_rates_i.append(r_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a pandas df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_rate_ie = np.array(all_pruning_ie)\n",
    "pruning_rate_ee = np.array(all_pruning_ee)\n",
    "rate_e = np.array(all_rates_e)\n",
    "rate_i = np.array(all_rates_i)\n",
    "big_ee = np.array(all_bigweights_ee)\n",
    "big_ie = np.array(all_bigweights_ie)\n",
    "files = np.array(files)\n",
    "\n",
    "print(files.shape)\n",
    "print(pruning_rate_ee.shape)\n",
    "df_data = {\"last_pruning_rate_ie\" : pruning_rate_ie[:,-1],\n",
    "           \"last_pruning_rate_ee\" : pruning_rate_ee[:,-1],\n",
    "           \"last_rate_e\" : rate_e[:,-1],\n",
    "           \"last_rate_i\" : rate_i[:,-1],\n",
    "           \"last_big_ee\" : big_ee[:,-1],\n",
    "           \"last_big_ie\" : big_ie[:,-1],\n",
    "           'files' : files\n",
    "           }\n",
    "\n",
    "df =pd.DataFrame(df_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out the good simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = df[(df['last_pruning_rate_ie'] < 200) & (df['last_pruning_rate_ee'] < 200) & (df['last_big_ee'] < 0.2) &  (df['last_big_ie'] < 0.2)]\n",
    "good_files = set(good['files'].values) \n",
    "bad_files = set(files) - good_files\n",
    "print(f\" Found {len(good_files)} examples so far ...\")\n",
    "print(f\" Found {len(bad_files)} example that can be deleted ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the bad files from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bad in bad_files:\n",
    "    os.remove(bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the good files into a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('good.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(good_files)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
